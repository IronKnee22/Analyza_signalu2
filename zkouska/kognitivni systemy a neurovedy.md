# ShrnutÃ­ ke zkouÅ¡ce: Klasifikace a shlukovÃ¡ analÃ½za

## ğŸ§  Co je klasifikace?
- PÅ™iÅ™azenÃ­ objektu do jednÃ© z pÅ™edem znÃ¡mÃ½ch tÅ™Ã­d
- Objekt reprezentovÃ¡n vektorem pÅ™Ã­znakÅ¯ (features)
- PÅ™Ã­klady:
  - PÅ™edpovÄ›Ä ÃºspÄ›Å¡nosti studentÅ¯
  - Diagnostika pacientÅ¯ na zÃ¡kladÄ› symptomÅ¯

---

## ğŸ”¢ Klasifikace vs. regrese
- **Klasifikace**: vÃ½stupem je tÅ™Ã­da (napÅ™. zdravÃ½/nemocnÃ½)
- **Regrese**: vÃ½stupem je reÃ¡lnÃ© ÄÃ­slo (napÅ™. predikce teploty)

---

## âš™ï¸ ZÃ¡kladnÃ­ klasifikÃ¡tory

### ğŸ“ K-NN (Nearest Neighbor)
- 1-NN: vezme nejbliÅ¾Å¡Ã­ soused
- K-NN: vezme K nejbliÅ¾Å¡Ã­ch a rozhodne podle vÄ›tÅ¡iny
- VÃ½hody: jednoduchost, rychlÃ© uÄenÃ­
- NevÃ½hody: pomalÃ¡ predikce, neefektivnÃ­ u velkÃ©ho mnoÅ¾stvÃ­ pÅ™Ã­znakÅ¯

### ğŸ§  BayesovskÃ© klasifikÃ¡tory
- VyuÅ¾Ã­vajÃ­ Bayesovu vÄ›tu k vÃ½poÄtu pravdÄ›podobnosti tÅ™Ã­d

### ğŸŒ² RozhodovacÃ­ stromy
- Indukce stromu â†’ rozhodovÃ¡nÃ­ â†’ pÅ™Ã­padnÄ› proÅ™ezÃ¡nÃ­
- VÃ½hody: jednoduchost, pravidla
- NevÃ½hody: horÅ¡Ã­ pro spojitÃ¡ data nebo chybÄ›jÃ­cÃ­ hodnoty

### ğŸŒ³ Random Forest
- Kombinace mnoha rozhodovacÃ­ch stromÅ¯ (ensemble learning)

### ğŸ’¡ SVM (Support Vector Machine)
- MaximÃ¡lnÃ­ margin mezi tÅ™Ã­dami, pouÅ¾Ã­vÃ¡ support vektory
- KernelovÃ¡ metoda umoÅ¾Åˆuje nelineÃ¡rnÃ­ dÄ›lenÃ­ prostoru

### ğŸ”— NeuronovÃ© sÃ­tÄ›
- SloÅ¾itÄ›jÅ¡Ã­ modely schopnÃ© uÄenÃ­ z velkÃ©ho mnoÅ¾stvÃ­ dat

---

## ğŸ§ª Meta klasifikÃ¡tory
- **Bagging**: bootstrap a kombinace modelÅ¯
- **Boosting**: iterativnÃ­ zlepÅ¡ovÃ¡nÃ­
- **Stacking**: kombinace rÅ¯znÃ½ch modelÅ¯

---

## ğŸ§¼ PÅ™edzpracovÃ¡nÃ­ dat

### ğŸ” Detekce outlierÅ¯
- Hodnoty mimo rozsah â†’ mohou ovlivnit klasifikÃ¡tor
- ZobrazenÃ­: napÅ™. boxplot

### ğŸ§® Normalizace a selekce pÅ™Ã­znakÅ¯
- VÃ½bÄ›r nejvhodnÄ›jÅ¡Ã­ch vlastnostÃ­ (kritÃ©ria: pÅ™esnost, entropie...)
- Metody: individual ranking, SFS, SBE, evoluÄnÃ­ algoritmy

### ğŸ“‰ Redukce rozmÄ›ru
- NapÅ™. PCA (Principal Component Analysis)

### âš ï¸ NerovnomÄ›rnÃ© zastoupenÃ­ tÅ™Ã­d
- ProblÃ©m: nevyvÃ¡Å¾enÃ½ dataset
- Å˜eÅ¡enÃ­: undersampling, oversampling

---

## ğŸ“ˆ HodnocenÃ­ klasifikÃ¡toru

### ğŸ“Š Metody:
- Accuracy = (TP+TN)/(celkem)
- Sensitivity (Recall) = TP / (TP + FN)
- Specificity = TN / (TN + FP)

### ğŸ“‰ ROC kÅ™ivka:
- Zobrazuje vztah mezi senzitivou a specificitou
- AUC = plocha pod ROC kÅ™ivkou

---

## ğŸ”„ Generalizace a testovÃ¡nÃ­

- **Hold-out metoda**: data rozdÄ›lena na trÃ©novacÃ­/testovacÃ­
- **KÅ™Ã­Å¾ovÃ¡ validace (Cross-validation)**: napÅ™. 5-fold
- CÃ­l: vyhnout se **overfittingu**

---

## ğŸ§¬ ShlukovÃ¡ analÃ½za (Clustering)
- **CÃ­l**: najÃ­t pÅ™irozenÃ© skupiny v datech (bez uÄitele)
- **K-means**: zadÃ¡me poÄet shlukÅ¯ K, algoritmus je najde
- **HierarchickÃ© shlukovÃ¡nÃ­**: vÃ½stup = dendrogram

---

## ğŸ“ ShrnutÃ­

- VÃ½bÄ›r kvalitnÃ­ch pÅ™Ã­znakÅ¯
- SprÃ¡vnÃ© dÄ›lenÃ­ dat na trÃ©novacÃ­/testovacÃ­ mnoÅ¾inu
- VhodnÃ½ klasifikÃ¡tor a zpÅ¯sob hodnocenÃ­ (ROC, AUC, senzitivita...)
- Nejprve zkouÅ¡et jednoduchÃ© modely (K-NN, stromy), pozdÄ›ji sloÅ¾itÄ›jÅ¡Ã­ (SVM, ANN)


